{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting job list from google job search\n",
    "\n",
    "# Importing libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import gspread\n",
    "\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "job_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_selenium():\n",
    "\n",
    "    # Configure selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Set user data directory to avoid logging in every time\n",
    "    options.add_argument(f\"user-data-dir=E:\\\\Repository\\\\data-jobs-in-indonesia\\\\Browser data\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    return driver\n",
    "\n",
    "def load_all_jobs(driver, left_pane):\n",
    "    # Scroll to the bottom of the list until all jobs are loaded\n",
    "    all_jobs_loaded = False\n",
    "    while not all_jobs_loaded:\n",
    "\n",
    "        # Get old scroll height\n",
    "        previous_scroll_height = driver.execute_script(\"return arguments[0].scrollHeight;\", left_pane)\n",
    "\n",
    "        # Scroll to bottom of the list (fetches more jobs)\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", left_pane)\n",
    "\n",
    "        # Grant some time for messages to load\n",
    "        sleep(1)\n",
    "\n",
    "        # Get current scroll height\n",
    "        current_scroll_height = driver.execute_script(\"return arguments[0].scrollHeight;\", left_pane)\n",
    "        # Check if all messages were loaded by comparing the scroll heights\n",
    "        if current_scroll_height == previous_scroll_height:\n",
    "            # Scroll back to top of the list to start collecting jobs\n",
    "            driver.execute_script(\"arguments[0].scrollTop = 0\", left_pane)\n",
    "            all_jobs_loaded = True\n",
    "\n",
    "def get_jobs(driver, left_pane):\n",
    "    # Looping through jobs list\n",
    "    for job in left_pane.find_elements(By.TAG_NAME, 'li'):\n",
    "        # Clicking on the job\n",
    "        job.click()\n",
    "\n",
    "        # Getting job details\n",
    "        # Extract details information\n",
    "        job_title = job.find_element(By.CLASS_NAME, 'BjJfJf').text\n",
    "        company_name = job.find_element(By.CLASS_NAME, 'vNEEBe').text\n",
    "        location = job.find_element(By.CLASS_NAME, 'Qk80Jf').text\n",
    "        # Extract details after via based on the value it contains\n",
    "        details = job.find_element(By.CLASS_NAME, 'PwjeAc').text.split('\\n')\n",
    "        via = ''\n",
    "        raw_date_posted = ''\n",
    "        salary = ''\n",
    "        job_type = ''\n",
    "        for i in details:\n",
    "            if 'melalui' in i:\n",
    "                via = i\n",
    "            elif 'yang' in i:\n",
    "                raw_date_posted = i\n",
    "            elif 'Rp' in i:\n",
    "                salary = i\n",
    "            else:\n",
    "                job_type = i\n",
    "\n",
    "        # Getting job description from right pane\n",
    "        description_pane = driver.find_element(By.CLASS_NAME, 'whazf')\n",
    "        # Try if description is expandable\n",
    "        try:\n",
    "            # Expand the description\n",
    "            description_pane.find_element(By.CLASS_NAME, 'mjkhcd').click()\n",
    "            WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, 'config-text-expandable')))\n",
    "            description = description_pane.find_element(By.CLASS_NAME, 'config-text-expandable').text\n",
    "        except NoSuchElementException:\n",
    "            description = description_pane.find_element(By.CLASS_NAME, 'HBvzbc').text\n",
    "\n",
    "        # Append to job_results\n",
    "        job_results.append([job_title, company_name, location, via, raw_date_posted, salary, job_type, description])\n",
    "\n",
    "def convert_salary(text):\n",
    "    text = text.replace('Rp ', '').replace('.', '').replace(' rb', '000').replace('per bulan', '')\n",
    "    if re.search(r'(\\d),(\\d{2}) jt', text):\n",
    "        text = text.replace(' jt', '0000')\n",
    "    elif re.search(r'(\\d),(\\d) jt', text):\n",
    "        text = text.replace(' jt', '00000')\n",
    "    else:\n",
    "        text = text.replace(' jt', '000000')\n",
    "\n",
    "    return int(text.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the script\n",
    "job_results.clear()\n",
    "driver = setup_selenium()\n",
    "job_search = ['data+analyst', 'data+scientist', 'data+engineer']\n",
    "\n",
    "# Loop Through Job Search\n",
    "for job in job_search:\n",
    "    driver.get(f'https://www.google.com/search?q={job}&ibp=htl;jobs#htivrt=jobs&fpstate=tldetail&htilrad=-1.0&htidocid')\n",
    "\n",
    "    # Wait for the page to load\n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.TAG_NAME, 'li')))\n",
    "    left_pane = driver.find_element(By.CLASS_NAME, 'zxU94d')\n",
    "    load_all_jobs(driver, left_pane)\n",
    "    get_jobs(driver, left_pane)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(job_results, columns=['job_title', 'company_name', 'location', 'via', 'raw_date_posted', 'salary', 'job_type', 'description'])\n",
    "df = df.drop_duplicates(subset=['job_title', 'company_name', 'location', 'via', 'salary'])\n",
    "df.to_csv('job_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset dataframe\n",
    "df = pd.DataFrame(job_results, columns=['job_title', 'company_name', 'location', 'via', 'raw_date_posted', 'salary', 'job_type', 'description'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and Standardize Data\n",
    "# Convert raw_date_posted to correct dd/mm/yyyy format\n",
    "df['date_posted'] = df['raw_date_posted'].apply(lambda x: datetime.today().date() - timedelta(days=int(x.split(' ')[0])) if 'hari' in x else datetime.today().date() if 'jam' in x else '' if 'bulan' in x else x)\n",
    "# Remove 'melalu' from via column\n",
    "df['posted_via'] = df['via'].str.replace('melalui', '')\n",
    "# Remove '(+n lainnya)' from location column using regex\n",
    "df['location'] = df['location'].apply(lambda x: re.sub(r' \\(\\+\\d+ lainnya\\)', '', x))\n",
    "# Get the city from location column\n",
    "df['city'] = df['location'].apply(lambda x: x.split(',')[0] if x != '' else x)\n",
    "df['city'] = df['city'].str.replace('Kota ', '').str.replace('Kab. ', '').str.replace('Kabupaten ', '')\n",
    "# Get the province from location column\n",
    "df['province'] = df['location'].apply(lambda x: x.split(',')[-1].strip() if x != '' else x)\n",
    "# Clean Salary\n",
    "# Drop row if salary contain 'per hari' or 'per tahun'\n",
    "df = df[~df['salary'].str.contains('per hari|per tahun')]\n",
    "# Split salary into min_salary & max_salary\n",
    "df['min_salary'] = df['salary'].apply(lambda x: convert_salary(x.split('–')[0]) if '–' in x else convert_salary(x) if x !='' else x)\n",
    "df['max_salary'] = df['salary'].apply(lambda x: convert_salary(x.split('–')[1]) if '–' in x else convert_salary(x) if x !='' else x)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('E:/Repository/data-jobs-in-indonesia/job_list.csv')\n",
    "# df = df.drop_duplicates(subset=['job_title', 'company_name', 'location', 'salary'])\n",
    "# # df = df.fillna('')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the data\n",
    "cols_order = ['date_posted', 'job_title', 'company_name', 'city', 'province', 'min_salary', 'max_salary', 'posted_via', 'job_type', 'description']\n",
    "final_df = df[cols_order].fillna('')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Sheets API and update worksheet\n",
    "scope = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "        \"https://www.googleapis.com/auth/drive.file\",\n",
    "        \"https://www.googleapis.com/auth/drive\"]\n",
    "keyfile_path = os.path.join(os.getcwd(), 'credentials.json')\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(keyfile_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "spreadsheet = client.open('jobs_data')\n",
    "worksheet = spreadsheet.worksheet('selenium_data')\n",
    "\n",
    "# Convert DataFrame to a list of lists\n",
    "data = [cols_order] + final_df.sort_values(by='date_posted', ascending=False).values.tolist()\n",
    "\n",
    "# Write the data to the worksheet\n",
    "worksheet.update(range_name='A1', values=data, raw=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "df = pd.read_csv('E:/Repository/data-jobs-in-indonesia/job_list.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract years of experience from description column if contains 'years' followed by 'experience'\n",
    "df['experience'] = df['description'].apply(lambda x: re.search(r'\\d+ years? experience', x) if x != '' else x)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.experience.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only rows with salary_clean not null\n",
    "isi = df[df['salary_clean'] != '']\n",
    "isi.salary_clean[6].split('–')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = setup_selenium()\n",
    "driver.get('https://www.google.com/search?q=data+analyst&ibp=htl;jobs#htivrt=jobs&fpstate=tldetail&htilrad=-1.0&htidocid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting job description from right pane\n",
    "description_pane = driver.find_element(By.CLASS_NAME, 'whazf')\n",
    "\n",
    "# Try if description is expandable\n",
    "try:\n",
    "    # Expand the description\n",
    "    description_pane.find_element(By.CLASS_NAME, 'mjkhcd').click()\n",
    "    WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, 'config-text-expandable')))\n",
    "    description = description_pane.find_element(By.CLASS_NAME, 'config-text-expandable').text\n",
    "except NoSuchElementException:\n",
    "    description = description_pane.find_element(By.CLASS_NAME, 'HBvzbc').text\n",
    "\n",
    "print(description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
